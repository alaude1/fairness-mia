{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install aif360\n",
    "!pip install BlackBoxAuditing\n",
    "!pip install fairlearn==0.4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sophie/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import AdultDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0425 15:08:50.609015 140402936649536 standard_dataset.py:101] Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    }
   ],
   "source": [
    "ad = AdultDataset(instance_weights_name='fnlwgt', features_to_drop=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_train, ad_test = ad.split(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconstrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from copy import deepcopy\n",
    "from aif360.metrics import ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df_train, ad_attrs_train = ad_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)\n",
    "ad_df_test, ad_attrs_test = ad_test.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(ad_df_train[['income-per-year']]).reshape(((len(ad_df_train),))).astype(int)\n",
    "Xs_train = np.array(ad_df_train.drop(columns='income-per-year'))\n",
    "Y_test = np.array(ad_df_test[['income-per-year']]).reshape(((len(ad_df_test),))).astype(int)\n",
    "Xs_test = np.array(ad_df_test.drop(columns='income-per-year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 300, solver='liblinear').fit(Xs_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_train = clf.predict(Xs_train).reshape((len(Y_train), 1))\n",
    "predicted_labels = clf.predict(Xs_test).reshape((len(Y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pred = deepcopy(ad_test)\n",
    "ad_pred_train = deepcopy(ad_train)\n",
    "ad_pred.labels = predicted_labels\n",
    "ad_pred_train.labels = predicted_labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Test Accuracy: 0.8516964899300383\n",
      "Original Demographic Parity ratio: 0.5652787213393603\n",
      "Original Average Absolute Odds diff: 0.049887323350057494\n"
     ]
    }
   ],
   "source": [
    "u = [{'race': 0}]\n",
    "p = [{'race': 1}]\n",
    "metrics = ClassificationMetric(ad_test,ad_pred,unprivileged_groups=u, privileged_groups=p)\n",
    "test_acc = metrics.accuracy()\n",
    "DI = metrics.disparate_impact()\n",
    "EO = metrics.average_abs_odds_difference()\n",
    "print('Original Test Accuracy:', test_acc)\n",
    "print('Original Demographic Parity ratio:', DI)\n",
    "print('Original Average Absolute Odds diff:', EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mia.membership_inference_attacks import black_box_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membership inference attack\n",
    "\n",
    "# train shadow model\n",
    "shadow_train, shadow_test = ad_test.split(2)\n",
    "shadow_train_df, _ = shadow_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)\n",
    "shadow_test_df, _ = shadow_test.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)\n",
    "shadow_Y_train = np.array(shadow_train_df[['income-per-year']]).reshape(((len(shadow_train_df),))).astype(int)\n",
    "shadow_Xs_train = np.array(shadow_train_df.drop(columns='income-per-year'))\n",
    "shadow_Y_test = np.array(shadow_test_df[['income-per-year']]).reshape(((len(shadow_test_df),))).astype(int)\n",
    "shadow_Xs_test = np.array(shadow_test_df.drop(columns='income-per-year'))\n",
    "\n",
    "true_pred_on_shadow_train = clf.predict(shadow_Xs_train)\n",
    "true_pred_on_shadow_test = clf.predict(shadow_Xs_test)\n",
    "\n",
    "shadow_model = LogisticRegression(max_iter = 300, solver='liblinear').fit(shadow_Xs_train, true_pred_on_shadow_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs\n",
    "shadow_out_train = shadow_model.predict_proba(shadow_Xs_train)\n",
    "shadow_out_test = shadow_model.predict_proba(shadow_Xs_test)\n",
    "true_model_train = clf.predict_proba(Xs_train)\n",
    "true_model_test = clf.predict_proba(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_performance = (shadow_out_train, true_pred_on_shadow_train)\n",
    "shadow_test_performance = (shadow_out_test, true_pred_on_shadow_test)\n",
    "target_train_performance = (true_model_train, Y_train)\n",
    "target_test_performance = (true_model_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass=Federal-gov</th>\n",
       "      <th>workclass=Local-gov</th>\n",
       "      <th>workclass=Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country=Scotland</th>\n",
       "      <th>native-country=South</th>\n",
       "      <th>native-country=Taiwan</th>\n",
       "      <th>native-country=Thailand</th>\n",
       "      <th>native-country=Trinadad&amp;Tobago</th>\n",
       "      <th>native-country=United-States</th>\n",
       "      <th>native-country=Vietnam</th>\n",
       "      <th>native-country=Yugoslavia</th>\n",
       "      <th>income-per-year</th>\n",
       "      <th>race-sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24471</th>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24472</th>\n",
       "      <td>40.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24473</th>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24475</th>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24476</th>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education-num  race  sex  capital-gain  capital-loss  \\\n",
       "24471  23.0            9.0   1.0  0.0           0.0           0.0   \n",
       "24472  40.0           14.0   1.0  0.0           0.0        1876.0   \n",
       "24473  45.0           10.0   1.0  0.0           0.0           0.0   \n",
       "24475  22.0           10.0   1.0  1.0           0.0           0.0   \n",
       "24476  38.0           13.0   1.0  1.0           0.0           0.0   \n",
       "\n",
       "       hours-per-week  workclass=Federal-gov  workclass=Local-gov  \\\n",
       "24471            33.0                    0.0                  0.0   \n",
       "24472            35.0                    0.0                  1.0   \n",
       "24473            35.0                    0.0                  0.0   \n",
       "24475            40.0                    0.0                  0.0   \n",
       "24476            50.0                    0.0                  0.0   \n",
       "\n",
       "       workclass=Private  ...  native-country=Scotland  native-country=South  \\\n",
       "24471                1.0  ...                      0.0                   0.0   \n",
       "24472                0.0  ...                      0.0                   0.0   \n",
       "24473                0.0  ...                      0.0                   0.0   \n",
       "24475                1.0  ...                      0.0                   0.0   \n",
       "24476                1.0  ...                      0.0                   0.0   \n",
       "\n",
       "       native-country=Taiwan  native-country=Thailand  \\\n",
       "24471                    0.0                      0.0   \n",
       "24472                    0.0                      0.0   \n",
       "24473                    0.0                      0.0   \n",
       "24475                    0.0                      0.0   \n",
       "24476                    0.0                      0.0   \n",
       "\n",
       "       native-country=Trinadad&Tobago  native-country=United-States  \\\n",
       "24471                             0.0                           1.0   \n",
       "24472                             0.0                           1.0   \n",
       "24473                             0.0                           1.0   \n",
       "24475                             0.0                           1.0   \n",
       "24476                             0.0                           1.0   \n",
       "\n",
       "       native-country=Vietnam  native-country=Yugoslavia  income-per-year  \\\n",
       "24471                     0.0                        0.0              0.0   \n",
       "24472                     0.0                        0.0              0.0   \n",
       "24473                     0.0                        0.0              0.0   \n",
       "24475                     0.0                        0.0              0.0   \n",
       "24476                     0.0                        0.0              1.0   \n",
       "\n",
       "       race-sex  \n",
       "24471         2  \n",
       "24472         2  \n",
       "24473         2  \n",
       "24475         3  \n",
       "24476         3  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_df['race-sex'] = shadow_train_df['race'].astype(str) + '-' + shadow_train_df['sex'].astype(str)\n",
    "shadow_train_df['race-sex'] = shadow_train_df['race-sex'].astype('category').cat.codes\n",
    "shadow_test_df['race-sex'] = shadow_test_df['race'].astype(str) + '-' + shadow_test_df['sex'].astype(str)\n",
    "shadow_test_df['race-sex'] = shadow_test_df['race-sex'].astype('category').cat.codes\n",
    "ad_df_train['race-sex'] = ad_df_train['race'].astype(str) + '-' + ad_df_train['sex'].astype(str)\n",
    "ad_df_train['race-sex'] = ad_df_train['race-sex'].astype('category').cat.codes\n",
    "ad_df_test['race-sex'] = ad_df_test['race'].astype(str) + '-' + ad_df_test['sex'].astype(str)\n",
    "ad_df_test['race-sex'] = ad_df_test['race-sex'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MIA\n",
    "MIA = black_box_benchmarks(shadow_train_performance,shadow_test_performance,\n",
    "                         target_train_performance,target_test_performance,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For membership inference attack via correctness, the attack acc is 0.500, with train acc 0.847 and test acc 0.848\n",
      "For membership inference attack via confidence, group attr 0, the attack acc is 0.528\n",
      "For membership inference attack via confidence, group attr 1, the attack acc is 0.513\n",
      "For membership inference attack via confidence, group attr 2, the attack acc is 0.508\n",
      "For membership inference attack via confidence, group attr 3, the attack acc is 0.506\n",
      "For membership inference attack via confidence, the shadow attack acc is 0.510\n",
      "For membership inference attack via confidence, the attack acc is 0.501\n",
      "For membership inference attack via entropy, group attr 0, the attack acc is 0.520\n",
      "For membership inference attack via entropy, group attr 1, the attack acc is 0.513\n",
      "For membership inference attack via entropy, group attr 2, the attack acc is 0.506\n",
      "For membership inference attack via entropy, group attr 3, the attack acc is 0.506\n",
      "For membership inference attack via entropy, the shadow attack acc is 0.509\n",
      "For membership inference attack via entropy, the attack acc is 0.500\n",
      "For membership inference attack via modified entropy, group attr 0, the attack acc is 0.528\n",
      "For membership inference attack via modified entropy, group attr 1, the attack acc is 0.513\n",
      "For membership inference attack via modified entropy, group attr 2, the attack acc is 0.508\n",
      "For membership inference attack via modified entropy, group attr 3, the attack acc is 0.506\n",
      "For membership inference attack via modified entropy, the shadow attack acc is 0.510\n",
      "For membership inference attack via modified entropy, the attack acc is 0.501\n",
      "For membership inference attack via confidence, the attack acc is 0.500\n",
      "For membership inference attack via entropy, the attack acc is 0.501\n",
      "For membership inference attack via modified entropy, the attack acc is 0.500\n"
     ]
    }
   ],
   "source": [
    "MIA._mem_inf_benchmarks(shadow_train_df['race-sex'].astype(int), shadow_test_df['race-sex'].astype(int), ad_df_train['race-sex'].astype(int), ad_df_test['race-sex'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic Parity (Independence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feldman et al. Repair (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import aif360.algorithms.preprocessing as AIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repairer = AIF.DisparateImpactRemover(repair_level=1.0, sensitive_attribute='race')\n",
    "repaired_train = repairer.fit_transform(ad_train)\n",
    "repaired_test = repairer.fit_transform(ad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_df_train, repaired_attrs_train = repaired_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)\n",
    "repaired_df_test, repaired_attrs_test = repaired_test.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rep_train = np.array(repaired_df_train[['income-per-year']]).reshape(((len(repaired_df_train),)))\n",
    "Xs_rep_train = np.array(repaired_df_train.drop(columns='income-per-year'))\n",
    "\n",
    "Y_rep_test = np.array(repaired_df_test[['income-per-year']]).reshape(((len(repaired_df_test),)))\n",
    "Xs_rep_test = np.array(repaired_df_test.drop(columns='income-per-year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rep = LogisticRegression(max_iter = 300, solver='liblinear').fit(Xs_rep_train, Y_rep_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_rep = clf_rep.predict(Xs_rep_test).reshape((len(Y_rep_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pred_rep = deepcopy(ad_test)\n",
    "ad_pred_rep.labels = predicted_labels_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repair Test Accuracy: 0.8511096256954943\n",
      "Repair Demographic Parity ratio: 0.5748155706381144\n",
      "Repair Average Absolute Odds diff: 0.04189026077198628\n"
     ]
    }
   ],
   "source": [
    "metrics_rep = ClassificationMetric(ad_test,ad_pred_rep,unprivileged_groups=u, privileged_groups=p)\n",
    "test_acc_rep = metrics_rep.accuracy()\n",
    "DI_rep = metrics_rep.disparate_impact()\n",
    "EO_rep = metrics_rep.average_abs_odds_difference()\n",
    "print('Repair Test Accuracy:', test_acc_rep)\n",
    "print('Repair Demographic Parity ratio:', DI_rep)\n",
    "print('Repair Average Absolute Odds diff:', EO_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kamishima et al. Regularization (Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/sophie/.local/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/sophie/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.21.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.18.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/sophie/.local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/sophie/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: h5py in /home/sophie/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /home/sophie/.local/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (46.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sophie/.local/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/sophie/anaconda3/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import PrejudiceRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrejRemover = PrejudiceRemover(eta=0.1, sensitive_attr='race', class_attr='income-per-year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrejRemover = PrejRemover.fit(ad_train)\n",
    "kamishima_pred = PrejRemover.predict(ad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prej Remover Test Accuracy: 0.8453421761768007\n",
      "Prej Remover Demographic Parity ratio: 0.4978724331429025\n",
      "Prej Remover Average Absolute Odds diff: 0.0756202852512517\n"
     ]
    }
   ],
   "source": [
    "metrics_kamishima = ClassificationMetric(ad_test,kamishima_pred,unprivileged_groups=u, privileged_groups=p)\n",
    "test_acc_prej = metrics_kamishima.accuracy()\n",
    "DI_prej = metrics_kamishima.disparate_impact()\n",
    "EO_prej = metrics_kamishima.average_abs_odds_difference()\n",
    "print('Prej Remover Test Accuracy:', test_acc_prej)\n",
    "print('Prej Remover Demographic Parity ratio:', DI_prej)\n",
    "print('Prej Remover Average Absolute Odds diff:', EO_prej)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agarwal et al (Reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing.exponentiated_gradient_reduction import ExponentiatedGradientReduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(solver='liblinear')\n",
    "np.random.seed(0) #need for reproducibility\n",
    "exp_grad_red_dp = ExponentiatedGradientReduction(estimator=estimator, \n",
    "                                              constraints=\"DemographicParity\",\n",
    "                                              drop_prot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "exp_grad_red_dp.fit(ad_train)\n",
    "exp_grad_red_pred_dp = exp_grad_red_dp.predict(ad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Reduction Test Accuracy: 0.8320405411045667\n",
      "DP Reduction Demographic Parity ratio: 0.9469555766712154\n",
      "DP Reduction Average Absolute Odds diff: 0.0630372657437408\n"
     ]
    }
   ],
   "source": [
    "metrics_red_dp = ClassificationMetric(ad_test,exp_grad_red_pred_dp,unprivileged_groups=u, privileged_groups=p)\n",
    "test_acc_red_dp = metrics_red_dp.accuracy()\n",
    "DI_red_dp = metrics_red_dp.disparate_impact()\n",
    "EO_red_dp = metrics_red_dp.average_abs_odds_difference()\n",
    "print('DP Reduction Test Accuracy:', test_acc_red_dp)\n",
    "print('DP Reduction Demographic Parity ratio:', DI_red_dp)\n",
    "print('DP Reduction Average Absolute Odds diff:', EO_red_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equalized Odds (Separation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardt et al. (Postprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing = EqOddsPostprocessing(u, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing = postprocessing.fit(ad_train, ad_pred_train)\n",
    "postprocess_pred = postprocessing.predict(ad_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessing Test Accuracy: 0.8429309786202139\n",
      "Postprocessing Demographic Parity ratio: 0.7083046158936913\n",
      "Postprocessing Average Absolute Odds diff: 0.016684602600477202\n"
     ]
    }
   ],
   "source": [
    "metrics_post = ClassificationMetric(ad_test,postprocess_pred,unprivileged_groups=u, privileged_groups=p)\n",
    "test_acc_post = metrics_post.accuracy()\n",
    "DI_post = metrics_post.disparate_impact()\n",
    "EO_ppost = metrics_post.average_abs_odds_difference()\n",
    "print('Postprocessing Test Accuracy:', test_acc_post)\n",
    "print('Postprocessing Demographic Parity ratio:', DI_post)\n",
    "print('Postprocessing Average Absolute Odds diff:', EO_ppost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agarwal et al (Reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(solver='liblinear')\n",
    "np.random.seed(0) #need for reproducibility\n",
    "exp_grad_red = ExponentiatedGradientReduction(estimator=estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "exp_grad_red.fit(ad_train)\n",
    "exp_grad_red_pred = exp_grad_red.predict(ad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EO Reduction Test Accuracy: 0.8395849432292414\n",
      "EO Reduction Demographic Parity ratio: 0.6803765727104913\n",
      "EO Reduction Average Absolute Odds diff: 0.009446494651760642\n"
     ]
    }
   ],
   "source": [
    "metrics_red_eo = ClassificationMetric(ad_test,exp_grad_red_pred,unprivileged_groups=u, privileged_groups=p)\n",
    "test_acc_red_eo = metrics_red_eo.accuracy()\n",
    "DI_red_eo = metrics_red_eo.disparate_impact()\n",
    "EO_red_eo = metrics_red_eo.average_abs_odds_difference()\n",
    "print('EO Reduction Test Accuracy:', test_acc_red_eo)\n",
    "print('EO Reduction Demographic Parity ratio:', DI_red_eo)\n",
    "print('EO Reduction Average Absolute Odds diff:', EO_red_eo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "# Membership inference attack\n",
    "\n",
    "# train shadow model\n",
    "true_pred_on_shadow_train = exp_grad_red.predict(shadow_train)\n",
    "true_pred_on_shadow_test = exp_grad_red.predict(shadow_test)\n",
    "\n",
    "shadow_model = LogisticRegression(max_iter = 300, solver='liblinear').fit(shadow_Xs_train, true_pred_on_shadow_train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_train = pd.DataFrame(ad_train.features, columns=ad_train.feature_names)\n",
    "X_df_test = pd.DataFrame(ad_test.features, columns=ad_test.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs\n",
    "shadow_out_train = shadow_model.predict_proba(shadow_Xs_train)\n",
    "shadow_out_test = shadow_model.predict_proba(shadow_Xs_test)\n",
    "true_model_train = exp_grad_red.model.predict_proba(X_df_train)\n",
    "true_model_test = exp_grad_red.model.predict_proba(X_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e1ce91cdbb02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue_pred_on_shadow_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_pred_on_shadow_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pred_on_shadow_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrue_pred_on_shadow_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_pred_on_shadow_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pred_on_shadow_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "true_pred_on_shadow_train = true_pred_on_shadow_train.labels.astype(int).reshape(len(true_pred_on_shadow_train.labels),)\n",
    "true_pred_on_shadow_test = true_pred_on_shadow_test.labels.astype(int).reshape(len(true_pred_on_shadow_test.labels),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_train_performance = (shadow_out_train, true_pred_on_shadow_train)\n",
    "shadow_test_performance = (shadow_out_test, true_pred_on_shadow_test)\n",
    "target_train_performance = (true_model_train, Y_train)\n",
    "target_test_performance = (true_model_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MIA\n",
    "MIA = black_box_benchmarks(shadow_train_performance,shadow_test_performance,\n",
    "                         target_train_performance,target_test_performance,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For membership inference attack via correctness, the attack acc is 0.500, with train acc 0.846 and test acc 0.846\n",
      "For membership inference attack via confidence, group attr 0, the attack acc is 0.523\n",
      "For membership inference attack via confidence, group attr 1, the attack acc is 0.507\n",
      "For membership inference attack via confidence, group attr 2, the attack acc is 0.507\n",
      "For membership inference attack via confidence, group attr 3, the attack acc is 0.506\n",
      "For membership inference attack via confidence, the shadow attack acc is 0.508\n",
      "For membership inference attack via confidence, the attack acc is 0.500\n",
      "For membership inference attack via entropy, group attr 0, the attack acc is 0.520\n",
      "For membership inference attack via entropy, group attr 1, the attack acc is 0.512\n",
      "For membership inference attack via entropy, group attr 2, the attack acc is 0.507\n",
      "For membership inference attack via entropy, group attr 3, the attack acc is 0.506\n",
      "For membership inference attack via entropy, the shadow attack acc is 0.509\n",
      "For membership inference attack via entropy, the attack acc is 0.499\n",
      "For membership inference attack via modified entropy, group attr 0, the attack acc is 0.523\n",
      "For membership inference attack via modified entropy, group attr 1, the attack acc is 0.507\n",
      "For membership inference attack via modified entropy, group attr 2, the attack acc is 0.507\n",
      "For membership inference attack via modified entropy, group attr 3, the attack acc is 0.506\n",
      "For membership inference attack via modified entropy, the shadow attack acc is 0.508\n",
      "For membership inference attack via modified entropy, the attack acc is 0.500\n",
      "For membership inference attack via confidence, the attack acc is 0.499\n",
      "For membership inference attack via entropy, the attack acc is 0.500\n",
      "For membership inference attack via modified entropy, the attack acc is 0.499\n"
     ]
    }
   ],
   "source": [
    "MIA._mem_inf_benchmarks(shadow_train_df['race-sex'].astype(int), shadow_test_df['race-sex'].astype(int), ad_df_train['race-sex'].astype(int), ad_df_test['race-sex'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
