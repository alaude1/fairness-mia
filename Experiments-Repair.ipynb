{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairlearn\n",
      "  Downloading fairlearn-0.6.1-py3-none-any.whl (24.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.6 MB 47 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from fairlearn) (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from fairlearn) (1.5.0)\n",
      "Requirement already satisfied: pandas>=0.25.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from fairlearn) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from fairlearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.1->fairlearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.1->fairlearn) (0.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.25.1->fairlearn) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.25.1->fairlearn) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas>=0.25.1->fairlearn) (1.15.0)\n",
      "Installing collected packages: fairlearn\n",
      "Successfully installed fairlearn-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fairness/data/preprocessed/adult_numerical.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove individuals in 'Other' race category\n",
    "data = data[data['race'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['A_race'] = data['race'].astype(\"category\").cat.codes\n",
    "data['A_sex'] = data['sex'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode race and sex\n",
    "data = pd.get_dummies(data, columns = ['race', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant columns\n",
    "data = data.drop(columns=['education-num', 'sex_Female', 'race_Amer-Indian-Eskimo',\n",
    "                   'workclass_Without-pay', 'education_1st-4th', 'marital-status_Never-married',\n",
    "                  'occupation_Other-service', 'relationship_Other-relative', 'native-country_Yugoslavia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make income-per-year binary\n",
    "data['Y'] = (data['income-per-year'] != '<=50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['income-per-year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get convert each combination of race and sex to a numerical category\n",
    "data['A_race-sex'] = data['race-sex'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['race-sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>A_race</th>\n",
       "      <th>A_sex</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>Y</th>\n",
       "      <th>A_race-sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  capital-gain  capital-loss  hours-per-week  workclass_Federal-gov  \\\n",
       "0   39          2174             0              40                      0   \n",
       "1   50             0             0              13                      0   \n",
       "2   38             0             0              40                      0   \n",
       "3   53             0             0              40                      0   \n",
       "4   28             0             0              40                      0   \n",
       "\n",
       "   workclass_Local-gov  workclass_Private  workclass_Self-emp-inc  \\\n",
       "0                    0                  0                       0   \n",
       "1                    0                  0                       0   \n",
       "2                    0                  1                       0   \n",
       "3                    0                  1                       0   \n",
       "4                    0                  1                       0   \n",
       "\n",
       "   workclass_Self-emp-not-inc  workclass_State-gov  ...  \\\n",
       "0                           0                    1  ...   \n",
       "1                           1                    0  ...   \n",
       "2                           0                    0  ...   \n",
       "3                           0                    0  ...   \n",
       "4                           0                    0  ...   \n",
       "\n",
       "   native-country_United-States  native-country_Vietnam  A_race  A_sex  \\\n",
       "0                             1                       0       3      1   \n",
       "1                             1                       0       3      1   \n",
       "2                             1                       0       3      1   \n",
       "3                             1                       0       2      1   \n",
       "4                             0                       0       2      0   \n",
       "\n",
       "   race_Asian-Pac-Islander  race_Black  race_White  sex_Male      Y  \\\n",
       "0                        0           0           1         1  False   \n",
       "1                        0           0           1         1  False   \n",
       "2                        0           0           1         1  False   \n",
       "3                        0           1           0         1  False   \n",
       "4                        0           1           0         0  False   \n",
       "\n",
       "   A_race-sex  \n",
       "0           7  \n",
       "1           7  \n",
       "2           7  \n",
       "3           5  \n",
       "4           4  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle rows for randomization\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data into 50% train and 50% test set\n",
    "sep = int(0.50 * len(data) + 0.5)\n",
    "train_data = data[:sep]\n",
    "test_data = data[sep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14966\n",
      "14965\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['Y', 'A_race', 'A_sex', 'A_race-sex'])\n",
    "X_test = test_data.drop(columns=['Y', 'A_race', 'A_sex', 'A_race-sex'])\n",
    "Y_train = train_data['Y']\n",
    "Y_test = test_data['Y']\n",
    "A_race_train = train_data['A_race']\n",
    "A_race_test = test_data['A_race']\n",
    "A_sex_train = train_data['A_sex']\n",
    "A_sex_test = test_data['A_sex']\n",
    "A_race_sex_train = train_data['A_race-sex']\n",
    "A_race_sex_test = test_data['A_race-sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feldman et al. Repair (Disparate Impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aif360\n",
      "  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from aif360) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from aif360) (1.0.5)\n",
      "Collecting tempeh\n",
      "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from aif360) (3.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from aif360) (0.23.1)\n",
      "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from aif360) (1.5.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->aif360) (2.8.1)\n",
      "Collecting memory-profiler\n",
      "  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n",
      "Collecting shap\n",
      "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
      "\u001b[K     |████████████████████████████████| 356 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tempeh->aif360) (2.24.0)\n",
      "Requirement already satisfied: pytest in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tempeh->aif360) (5.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->aif360) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->aif360) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->aif360) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->aif360) (7.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.1->aif360) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas>=0.24.0->aif360) (1.15.0)\n",
      "Requirement already satisfied: psutil in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from memory-profiler->tempeh->aif360) (5.7.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from shap->tempeh->aif360) (4.47.0)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from shap->tempeh->aif360) (0.50.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from shap->tempeh->aif360) (1.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests->tempeh->aif360) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests->tempeh->aif360) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests->tempeh->aif360) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests->tempeh->aif360) (1.25.9)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pytest->tempeh->aif360) (1.9.0)\n",
      "Requirement already satisfied: packaging in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pytest->tempeh->aif360) (20.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pytest->tempeh->aif360) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pytest->tempeh->aif360) (8.4.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from pytest->tempeh->aif360) (0.2.5)\n",
      "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (0.33.0+1.g022ab0f)\n",
      "Requirement already satisfied: setuptools in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from numba->shap->tempeh->aif360) (49.2.0.post20200714)\n",
      "Building wheels for collected packages: memory-profiler, shap\n",
      "  Building wheel for memory-profiler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30182 sha256=a16209c9426150376dd0acb398f252d68d373b78f9ed26c130f15c551415f201\n",
      "  Stored in directory: /Users/carinalewandowski/Library/Caches/pip/wheels/6a/37/3e/d9e8ebaf73956a3ebd2ee41869444dbd2a702d7142bcf93c42\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.39.0-cp38-cp38-macosx_10_9_x86_64.whl size=412981 sha256=d3d79015b4bb03880945e1c3434e84b3dfa8ec1d55beed4c2d832ad8c908640f\n",
      "  Stored in directory: /Users/carinalewandowski/Library/Caches/pip/wheels/3d/c9/06/734ed80d6d61fad331974bf62017b4ea6b33488082b9f5e67e\n",
      "Successfully built memory-profiler shap\n",
      "Installing collected packages: memory-profiler, slicer, shap, tempeh, aif360\n",
      "Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360.algorithms.preprocessing as AIF\n",
    "from aif360.datasets import AdultDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    }
   ],
   "source": [
    "ad = AdultDataset(instance_weights_name='fnlwgt', features_to_drop=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsingle_protected = ['sex']\\nsingle_privileged = [['Male']]\\nad = AdultDataset(protected_attribute_names=single_protected, privileged_classes=single_privileged,\\n                  categorical_features=[],\\n                  features_to_keep=['age', 'education-num'])\\n# check\\nprint(ad.feature_names)\\nprint(ad.label_names)\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate dataset \n",
    "'''\n",
    "single_protected = ['sex']\n",
    "single_privileged = [['Male']]\n",
    "ad = AdultDataset(protected_attribute_names=single_protected, privileged_classes=single_privileged,\n",
    "                  categorical_features=[],\n",
    "                  features_to_keep=['age', 'education-num'])\n",
    "# check\n",
    "print(ad.feature_names)\n",
    "print(ad.label_names)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlabel_map = {1.0: '>50K', 0.0: '<=50K'}\\nprotected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\\nad = AdultDataset(protected_attribute_names=['sex'],\\n                  privileged_classes=[['Male']], metadata={'label_map': label_map,\\n                                                           'protected_attribute_maps': protected_attribute_maps})\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep track of mapping from float -> str for proetected attributes and/or labels\n",
    "# use to modify mapping in 'metadata'\n",
    "'''\n",
    "label_map = {1.0: '>50K', 0.0: '<=50K'}\n",
    "protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "ad = AdultDataset(protected_attribute_names=['sex'],\n",
    "                  privileged_classes=[['Male']], metadata={'label_map': label_map,\n",
    "                                                           'protected_attribute_maps': protected_attribute_maps})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "repairer = AIF.DisparateImpactRemover(repair_level=1.0, sensitive_attribute='race')\n",
    "repaired_data = repairer.fit_transform(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_df, repaired_attrs = repaired_data.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)\n",
    "ad_df, ad_attrs = ad.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass=Federal-gov</th>\n",
       "      <th>workclass=Local-gov</th>\n",
       "      <th>workclass=Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country=Puerto-Rico</th>\n",
       "      <th>native-country=Scotland</th>\n",
       "      <th>native-country=South</th>\n",
       "      <th>native-country=Taiwan</th>\n",
       "      <th>native-country=Thailand</th>\n",
       "      <th>native-country=Trinadad&amp;Tobago</th>\n",
       "      <th>native-country=United-States</th>\n",
       "      <th>native-country=Vietnam</th>\n",
       "      <th>native-country=Yugoslavia</th>\n",
       "      <th>income-per-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education-num  race  sex  capital-gain  capital-loss  \\\n",
       "0      25.0            7.0   0.0  1.0           0.0           0.0   \n",
       "1      38.0            9.0   1.0  1.0           0.0           0.0   \n",
       "2      28.0           12.0   1.0  1.0           0.0           0.0   \n",
       "3      44.0           10.0   0.0  1.0        7688.0           0.0   \n",
       "5      34.0            6.0   1.0  1.0           0.0           0.0   \n",
       "...     ...            ...   ...  ...           ...           ...   \n",
       "48837  27.0           12.0   1.0  0.0           0.0           0.0   \n",
       "48838  40.0            9.0   1.0  1.0           0.0           0.0   \n",
       "48839  58.0            9.0   1.0  0.0           0.0           0.0   \n",
       "48840  22.0            9.0   1.0  1.0           0.0           0.0   \n",
       "48841  52.0            9.0   1.0  0.0       15024.0           0.0   \n",
       "\n",
       "       hours-per-week  workclass=Federal-gov  workclass=Local-gov  \\\n",
       "0                40.0                    0.0                  0.0   \n",
       "1                50.0                    0.0                  0.0   \n",
       "2                40.0                    0.0                  1.0   \n",
       "3                40.0                    0.0                  0.0   \n",
       "5                30.0                    0.0                  0.0   \n",
       "...               ...                    ...                  ...   \n",
       "48837            38.0                    0.0                  0.0   \n",
       "48838            40.0                    0.0                  0.0   \n",
       "48839            40.0                    0.0                  0.0   \n",
       "48840            20.0                    0.0                  0.0   \n",
       "48841            40.0                    0.0                  0.0   \n",
       "\n",
       "       workclass=Private  ...  native-country=Puerto-Rico  \\\n",
       "0                    1.0  ...                         0.0   \n",
       "1                    1.0  ...                         0.0   \n",
       "2                    0.0  ...                         0.0   \n",
       "3                    1.0  ...                         0.0   \n",
       "5                    1.0  ...                         0.0   \n",
       "...                  ...  ...                         ...   \n",
       "48837                1.0  ...                         0.0   \n",
       "48838                1.0  ...                         0.0   \n",
       "48839                1.0  ...                         0.0   \n",
       "48840                1.0  ...                         0.0   \n",
       "48841                0.0  ...                         0.0   \n",
       "\n",
       "       native-country=Scotland  native-country=South  native-country=Taiwan  \\\n",
       "0                          0.0                   0.0                    0.0   \n",
       "1                          0.0                   0.0                    0.0   \n",
       "2                          0.0                   0.0                    0.0   \n",
       "3                          0.0                   0.0                    0.0   \n",
       "5                          0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "48837                      0.0                   0.0                    0.0   \n",
       "48838                      0.0                   0.0                    0.0   \n",
       "48839                      0.0                   0.0                    0.0   \n",
       "48840                      0.0                   0.0                    0.0   \n",
       "48841                      0.0                   0.0                    0.0   \n",
       "\n",
       "       native-country=Thailand  native-country=Trinadad&Tobago  \\\n",
       "0                          0.0                             0.0   \n",
       "1                          0.0                             0.0   \n",
       "2                          0.0                             0.0   \n",
       "3                          0.0                             0.0   \n",
       "5                          0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "48837                      0.0                             0.0   \n",
       "48838                      0.0                             0.0   \n",
       "48839                      0.0                             0.0   \n",
       "48840                      0.0                             0.0   \n",
       "48841                      0.0                             0.0   \n",
       "\n",
       "       native-country=United-States  native-country=Vietnam  \\\n",
       "0                               1.0                     0.0   \n",
       "1                               1.0                     0.0   \n",
       "2                               1.0                     0.0   \n",
       "3                               1.0                     0.0   \n",
       "5                               1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "48837                           1.0                     0.0   \n",
       "48838                           1.0                     0.0   \n",
       "48839                           1.0                     0.0   \n",
       "48840                           1.0                     0.0   \n",
       "48841                           1.0                     0.0   \n",
       "\n",
       "       native-country=Yugoslavia  income-per-year  \n",
       "0                            0.0              0.0  \n",
       "1                            0.0              0.0  \n",
       "2                            0.0              1.0  \n",
       "3                            0.0              1.0  \n",
       "5                            0.0              0.0  \n",
       "...                          ...              ...  \n",
       "48837                        0.0              0.0  \n",
       "48838                        0.0              1.0  \n",
       "48839                        0.0              0.0  \n",
       "48840                        0.0              0.0  \n",
       "48841                        0.0              1.0  \n",
       "\n",
       "[45222 rows x 99 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rep = np.array(repaired_df[['income-per-year']]).reshape(((len(repaired_df),)))\n",
    "Xs_rep = np.array(repaired_df.drop(columns='income-per-year'))\n",
    "Y = np.array(ad_df[['income-per-year']]).reshape(((len(ad_df),)))\n",
    "Xs = np.array(ad_df.drop(columns='income-per-year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 98)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter = 300).fit(Xs, Y)\n",
    "clf_rep = LogisticRegression(max_iter = 300).fit(Xs_rep, Y_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original accuracy:  0.8440582017602052\n",
      "accuracy on repaired data:  0.8431957896599\n"
     ]
    }
   ],
   "source": [
    "acc = clf.score(Xs, Y)\n",
    "predicted_labels = clf.predict(Xs).reshape((len(Y), 1))\n",
    "print('original accuracy: ', acc)\n",
    "\n",
    "acc_rep = clf_rep.score(Xs_rep, Y_rep)\n",
    "predicted_labels_rep = clf_rep.predict(Xs_rep).reshape((len(Y_rep), 1))\n",
    "print('accuracy on repaired data: ', acc_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pred = deepcopy(ad)\n",
    "ad_pred.labels = predicted_labels\n",
    "\n",
    "ad_pred_rep = deepcopy(ad)\n",
    "ad_pred_rep.labels = predicted_labels_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.metrics import ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Disparate Impact: 0.5753559616317514\n"
     ]
    }
   ],
   "source": [
    "u = [{'race': 0}]\n",
    "p = [{'race': 1}]\n",
    "metrics = ClassificationMetric(ad,ad_pred,unprivileged_groups=u, privileged_groups=p)\n",
    "DI = metrics.disparate_impact()\n",
    "print('Original Disparate Impact:', DI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact on Repaired Data: 0.690573938777518\n"
     ]
    }
   ],
   "source": [
    "metrics_rep = ClassificationMetric(ad,ad_pred_rep,unprivileged_groups=u, privileged_groups=p)\n",
    "DI_rep = metrics_rep.disparate_impact()\n",
    "print('Disparate Impact on Repaired Data:', DI_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamishima et al. Regularization (Prejudice Remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp38-cp38-macosx_10_11_x86_64.whl (173.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 173.9 MB 246 bytes/s a 0:00:01  |▏                               | 849 kB 3.2 MB/s eta 0:00:54     |▎                               | 1.4 MB 3.2 MB/s eta 0:00:54     |██▏                             | 12.0 MB 42.2 MB/s eta 0:00:04     |████▌                           | 24.3 MB 42.2 MB/s eta 0:00:04     |██████▏                         | 33.3 MB 72.6 MB/s eta 0:00:02     |████████                        | 43.4 MB 2.2 MB/s eta 0:01:01     |███████████▍                    | 61.7 MB 8.0 MB/s eta 0:00:14     |███████████▊                    | 63.5 MB 8.0 MB/s eta 0:00:14     |███████████▉                    | 64.4 MB 8.0 MB/s eta 0:00:14     |██████████████▏                 | 77.1 MB 4.7 MB/s eta 0:00:21     |██████████████▊                 | 80.1 MB 4.7 MB/s eta 0:00:20 |███████████████                 | 81.9 MB 4.7 MB/s eta 0:00:20     |████████████████▉               | 91.3 MB 4.6 MB/s eta 0:00:19     |█████████████████▌              | 95.1 MB 4.6 MB/s eta 0:00:18     |█████████████████▊              | 96.4 MB 4.6 MB/s eta 0:00:17██████████▏             | 98.9 MB 4.6 MB/s eta 0:00:17█████████████▌             | 100.3 MB 4.6 MB/s eta 0:00:17     |████████████████████▍           | 110.7 MB 56.1 MB/s eta 0:00:02     |██████████████████████          | 119.7 MB 56.1 MB/s eta 0:00:01     |██████████████████████▉         | 124.1 MB 66.0 MB/s eta 0:00:01�██████████▎        | 126.2 MB 66.0 MB/s eta 0:00:01 |██████████████████████████▍     | 143.6 MB 3.6 MB/s eta 0:00:09 0:00:07�█████████▉ | 167.3 MB 32.1 MB/s eta 0:00:01�██████████ | 168.8 MB 32.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 53.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.15.8-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 43.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 4.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 37.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 1.4 MB/s eta 0:00:01    |████▌                           | 2.2 MB 9.1 MB/s eta 0:00:02     |█████████████████████████▏      | 12.3 MB 1.4 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 45.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 24.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 9.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.29.0-py2.py3-none-any.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.0-py3-none-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 2.7 MB/s eta 0:00:01     |█████████████▌                  | 1.2 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 26.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 20.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/carinalewandowski/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 39.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=1dcf764bd14e643b426340c9f97c0d9037daa3f4582aaf209dfe65818cf4f166\n",
      "  Stored in directory: /Users/carinalewandowski/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl size=32304 sha256=cc384815864de5357e2b77b6e4ce9000eef0f6dc7ac9cd6012d888661cd67f99\n",
      "  Stored in directory: /Users/carinalewandowski/Library/Caches/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: pyasn1, pyasn1-modules, cachetools, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, wheel, grpcio, tensorboard-data-server, tensorboard-plugin-wit, numpy, absl-py, protobuf, tensorboard, gast, google-pasta, astunparse, termcolor, keras-preprocessing, wrapt, opt-einsum, tensorflow-estimator, flatbuffers, tensorflow\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.29.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.8 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.0 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360.algorithms.inprocessing as AIF_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrejRemover = AIF_inp.PrejudiceRemover(eta=1.0, sensitive_attr='race', class_attr='income-per-year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamishima_data = PrejRemover.fit_predict(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact on Repaired Data: 0.5496994960493873\n"
     ]
    }
   ],
   "source": [
    "metrics_kamishima = ClassificationMetric(ad,kamishima_data,unprivileged_groups=u, privileged_groups=p)\n",
    "DI_kamishima = metrics_kamishima.disparate_impact()\n",
    "print('Disparate Impact on Repaired Data:', DI_kamishima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Logistic Regression Model with Fairness Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.reductions import GridSearch, EqualizedOdds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    selection_rate, demographic_parity_difference, demographic_parity_ratio,\n",
    "    false_positive_rate, false_negative_rate,\n",
    "    false_positive_rate_difference, false_negative_rate_difference,\n",
    "    equalized_odds_difference)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_metrics_df(models_dict, y_true, group):\n",
    "    metrics_dict = {\n",
    "        \"Overall selection rate\": (\n",
    "            lambda x: selection_rate(y_true, x), True),\n",
    "        \"Demographic parity difference\": (\n",
    "            lambda x: demographic_parity_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"Demographic parity ratio\": (\n",
    "            lambda x: demographic_parity_ratio(y_true, x, sensitive_features=group), True),\n",
    "        \"------\": (lambda x: \"\", True),\n",
    "        \"False positive rate difference\": (\n",
    "            lambda x: false_positive_rate_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"False negative rate difference\": (\n",
    "            lambda x: false_negative_rate_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"Equalized odds difference\": (\n",
    "            lambda x: equalized_odds_difference(y_true, x, sensitive_features=group), True),\n",
    "        \"  ------\": (lambda x: \"\", True),\n",
    "        \"Overall AUC\": (\n",
    "            lambda x: roc_auc_score(y_true, x), False),\n",
    "        \"AUC difference\": (\n",
    "            lambda x: MetricFrame(roc_auc_score, y_true, x, sensitive_features=group).difference(method='between_groups'), False),\n",
    "    }\n",
    "    df_dict = {}\n",
    "    for metric_name, (metric_func, use_preds) in metrics_dict.items():\n",
    "        df_dict[metric_name] = [metric_func(preds) if use_preds else metric_func(scores) \n",
    "                                for model_name, (preds, scores) in models_dict.items()]\n",
    "    return pd.DataFrame.from_dict(df_dict, orient=\"index\", columns=models_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='ovr')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "model = LogisticRegression(max_iter=500, multi_class='ovr')\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unconstrained model accuracies:\n",
      "Train acc: 0.8427101429907791\n",
      "Test acc: 0.8471099231540261\n",
      "Overall generalization gap: -0.004399780163247047\n"
     ]
    }
   ],
   "source": [
    "print('Unconstrained model accuracies:')\n",
    "train_acc, test_acc = model.score(X_train, Y_train), model.score(X_test, Y_test)\n",
    "unconstrained_test_preds = model.predict(X_test)\n",
    "unconstrained_test_scores = model.predict_proba(X_test)[:, 1]\n",
    "print('Train acc:', train_acc)\n",
    "print('Test acc:', test_acc)\n",
    "print('Overall generalization gap:', train_acc - test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using postprocessing algorithm from Hardt et. al \"Equality of Opportunity in Supervised Learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_est = ThresholdOptimizer(\n",
    "    estimator=model,\n",
    "    constraints=\"equalized_odds\",\n",
    "    prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThresholdOptimizer(constraints='equalized_odds',\n",
       "                   estimator=LogisticRegression(max_iter=500,\n",
       "                                                multi_class='ovr'),\n",
       "                   prefit=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocess_est.fit(X_train, Y_train, sensitive_features=A_sex_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_preds_train = postprocess_est.predict(X_train, sensitive_features=A_sex_train)\n",
    "postprocess_preds_test = postprocess_est.predict(X_test, sensitive_features=A_sex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardt et al model accuracies:\n",
      "Train acc: 0.19256982493652278\n",
      "Test acc: 0.18757099899766122\n",
      "Overall generalization gap: 0.004998825938861556\n"
     ]
    }
   ],
   "source": [
    "print('Hardt et al model accuracies:')\n",
    "\n",
    "train_acc = sum(postprocess_preds_train != Y_train) / len(postprocess_preds_train)\n",
    "test_acc = sum(postprocess_preds_test != Y_test) / len(postprocess_preds_test)\n",
    "print('Train acc:', train_acc)\n",
    "print('Test acc:', test_acc)\n",
    "print('Overall generalization gap:', train_acc - test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unconstrained</th>\n",
       "      <th>Hardt et al.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall selection rate</th>\n",
       "      <td>0.207551</td>\n",
       "      <td>0.196525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity difference</th>\n",
       "      <td>0.2987</td>\n",
       "      <td>0.203715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic parity ratio</th>\n",
       "      <td>0.0787458</td>\n",
       "      <td>0.28086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False positive rate difference</th>\n",
       "      <td>0.159132</td>\n",
       "      <td>0.119589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False negative rate difference</th>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.548611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized odds difference</th>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.548611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall AUC</th>\n",
       "      <td>0.899805</td>\n",
       "      <td>0.713856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC difference</th>\n",
       "      <td>0.136121</td>\n",
       "      <td>0.258223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Unconstrained Hardt et al.\n",
       "Overall selection rate              0.207551     0.196525\n",
       "Demographic parity difference         0.2987     0.203715\n",
       "Demographic parity ratio           0.0787458      0.28086\n",
       "------                                                   \n",
       "False positive rate difference      0.159132     0.119589\n",
       "False negative rate difference      0.477778     0.548611\n",
       "Equalized odds difference           0.477778     0.548611\n",
       "  ------                                                 \n",
       "Overall AUC                         0.899805     0.713856\n",
       "AUC difference                      0.136121     0.258223"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = { 'Unconstrained': (unconstrained_test_preds, unconstrained_test_scores),\n",
    "    'Hardt et al.': (postprocess_preds_test, postprocess_preds_test)}\n",
    "get_metrics_df(models_dict, Y_test, A_race_sex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
